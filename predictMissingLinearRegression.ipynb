{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictMissingLinearRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmkDwF2P/LDhQeu248Vw6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marianeneiva/handlingMissingData/blob/main/predictMissingLinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEcnFWmwBdBP"
      },
      "source": [
        "#PREDICTING MISSING VALUES WITH LINEAR REGRESSION\n",
        "\n",
        "Previously *(on < insert your tv show here.. >... kidding)* I posted the article with [four ways to handle missing data with pandas](https://maribneiva.medium.com/4-ways-to-handle-missing-data-with-pandas-420a103a2105).\n",
        "\n",
        "At the end I gave a spoiler *(am I watching too much Netflix?)* about the next episode of my Medium and here it is! \n",
        "\n",
        "Today we will learn how to predict missing values using machine learning (more specifically: linear regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8ngLguKQoD"
      },
      "source": [
        "#Downloading data\n",
        "\n",
        "The first step is to download the data from https://www.kaggle.com/dansbecker/melbourne-housing-snapshot/home. I downloaded from Kaggle API but you can skip this step and download it manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgVtq4R6wkun",
        "outputId": "63c600d1-e792-4f44-8299-0e28a4d51e87"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/portfolio_dataScience\"\n",
        "\n",
        "#changing the working directory\n",
        "%cd /content/gdrive/My Drive/portfolio_dataScience\n",
        "#Check the present working directory using pwd command\n",
        "\n",
        "!kaggle datasets download -d dansbecker/melbourne-housing-snapshot\n",
        "!ls\n",
        "\n",
        "#unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/portfolio_dataScience\n",
            "Downloading melbourne-housing-snapshot.zip to /content/gdrive/My Drive/portfolio_dataScience\n",
            "  0% 0.00/451k [00:00<?, ?B/s]\n",
            "100% 451k/451k [00:00<00:00, 30.3MB/s]\n",
            "kaggle.json  melb_data.csv  melbourne-housing-snapshot.zip\n",
            "Archive:  melbourne-housing-snapshot.zip\n",
            "replace melb_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_yCsQ6WKkyj"
      },
      "source": [
        "#Importing data\n",
        "\n",
        "The previous step download the data to my google drive. Now it is time to import it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "kjRvSjbvwqZv",
        "outputId": "8cae7902-041c-4ba8-a8bf-973e452395e6"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "data = pd.read_csv('melb_data.csv')\n",
        "\n",
        "#showing the data\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Suburb</th>\n",
              "      <th>Address</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Method</th>\n",
              "      <th>SellerG</th>\n",
              "      <th>Date</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>85 Turner St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1480000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>3/12/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.7996</td>\n",
              "      <td>144.9984</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>25 Bloomburg St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1035000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/02/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8079</td>\n",
              "      <td>144.9934</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>5 Charles St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1465000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8093</td>\n",
              "      <td>144.9944</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>40 Federation La</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>850000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>4/03/2017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.7969</td>\n",
              "      <td>144.9969</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>55a Park St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1600000.0</td>\n",
              "      <td>VB</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>4/06/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.8072</td>\n",
              "      <td>144.9941</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Suburb           Address  ...             Regionname Propertycount\n",
              "0  Abbotsford      85 Turner St  ...  Northern Metropolitan        4019.0\n",
              "1  Abbotsford   25 Bloomburg St  ...  Northern Metropolitan        4019.0\n",
              "2  Abbotsford      5 Charles St  ...  Northern Metropolitan        4019.0\n",
              "3  Abbotsford  40 Federation La  ...  Northern Metropolitan        4019.0\n",
              "4  Abbotsford       55a Park St  ...  Northern Metropolitan        4019.0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPHzCHTKwqy"
      },
      "source": [
        "#Transforming the data\n",
        "\n",
        "Although some machine learning methods are able to deal with categorial data (strings, dates, among others), this is not the case of linear regression. \n",
        "\n",
        "Therefore, one import step is to transform all categorical attributes to numbers.\n",
        "\n",
        "The code below uses pandas to perform the required action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clNrGBXbe5m3"
      },
      "source": [
        "data.Address = pd.Categorical(data.Address).codes\n",
        "data.Suburb = pd.Categorical(data.Suburb).codes\n",
        "data.Type = pd.Categorical(data.Type).codes\n",
        "data.Method = pd.Categorical(data.Method).codes\n",
        "data.SellerG = pd.Categorical(data.SellerG).codes\n",
        "data.Date = pd.Categorical(data.Date).codes\n",
        "data.CouncilArea = pd.Categorical(data.CouncilArea).codes\n",
        "data.Regionname = pd.Categorical(data.Regionname).codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbsKT8_xLT3b"
      },
      "source": [
        "#Separate columns\n",
        "\n",
        "In this example, I will use only columns that does not contain null values. To do this automatically, we can use the isnull() function aligned with mean() (sum() would work as well).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m59MA47Gw6Q_",
        "outputId": "a2ec1142-65e4-4182-bcf9-4064a3e41bdd"
      },
      "source": [
        "dataNull = data[data.columns[data.isnull().mean() > 0]]\n",
        "dataNotNull = data[data.columns[data.isnull().mean() == 0]]\n",
        "\n",
        "print(dataNull)\n",
        "print(dataNotNull)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Car  BuildingArea  YearBuilt\n",
            "0      1.0           NaN        NaN\n",
            "1      0.0          79.0     1900.0\n",
            "2      0.0         150.0     1900.0\n",
            "3      1.0           NaN        NaN\n",
            "4      2.0         142.0     2014.0\n",
            "...    ...           ...        ...\n",
            "13575  2.0           NaN     1981.0\n",
            "13576  2.0         133.0     1995.0\n",
            "13577  4.0           NaN     1997.0\n",
            "13578  5.0         157.0     1920.0\n",
            "13579  1.0         112.0     1920.0\n",
            "\n",
            "[13580 rows x 3 columns]\n",
            "       Suburb  Address  Rooms  ...  Longtitude  Regionname  Propertycount\n",
            "0           0    12794      2  ...   144.99840           2         4019.0\n",
            "1           0     5943      2  ...   144.99340           2         4019.0\n",
            "2           0     9814      3  ...   144.99440           2         4019.0\n",
            "3           0     9004      3  ...   144.99690           2         4019.0\n",
            "4           0    10589      4  ...   144.99410           2         4019.0\n",
            "...       ...      ...    ...  ...         ...         ...            ...\n",
            "13575     302     1991      4  ...   145.16761           4         7392.0\n",
            "13576     305    12234      3  ...   144.87904           6         6380.0\n",
            "13577     305    12745      3  ...   144.88738           6         6380.0\n",
            "13578     305    13311      4  ...   144.89299           6         6380.0\n",
            "13579     313    10776      4  ...   144.88449           6         6543.0\n",
            "\n",
            "[13580 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOoJSDKYMt1y"
      },
      "source": [
        "#Training and test sets\n",
        "\n",
        "Yes, we could use k-fold or any other validation step to improve the confidence in the results. Also, we could use correlation analysis to chose the columns that are more related to the one we chose to predict.\n",
        "\n",
        "Yes, does additions would be great and I suggest you to keep them in mind for a bigger project. \n",
        "\n",
        "However, for the sake of simplicity, I will keep it basic for this post.\n",
        "\n",
        "Furthermore, in this example, we will predict BuildingArea column and the code is how I separate training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNXHg8XKx5cx",
        "outputId": "2be1171d-a50b-4e04-a082-dec37ae5c9d3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_test = dataNull[dataNull['BuildingArea'].isnull()]['BuildingArea']\n",
        "y_train = dataNull[~dataNull['BuildingArea'].isnull()]['BuildingArea']\n",
        "print(y_test)\n",
        "print(y_train)\n",
        "\n",
        "x_training = dataNotNull[~data['BuildingArea'].isnull()]\n",
        "x_test = dataNotNull[data['BuildingArea'].isnull()]\n",
        "\n",
        "print(x_training)\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       NaN\n",
            "3       NaN\n",
            "5       NaN\n",
            "8       NaN\n",
            "10      NaN\n",
            "         ..\n",
            "13569   NaN\n",
            "13570   NaN\n",
            "13574   NaN\n",
            "13575   NaN\n",
            "13577   NaN\n",
            "Name: BuildingArea, Length: 6450, dtype: float64\n",
            "1         79.0\n",
            "2        150.0\n",
            "4        142.0\n",
            "6        210.0\n",
            "7        107.0\n",
            "         ...  \n",
            "13572     79.0\n",
            "13573    172.0\n",
            "13576    133.0\n",
            "13578    157.0\n",
            "13579    112.0\n",
            "Name: BuildingArea, Length: 7130, dtype: float64\n",
            "       Suburb  Address  Rooms  ...  Longtitude  Regionname  Propertycount\n",
            "1           0     5943      2  ...   144.99340           2         4019.0\n",
            "2           0     9814      3  ...   144.99440           2         4019.0\n",
            "4           0    10589      4  ...   144.99410           2         4019.0\n",
            "6           0     2142      3  ...   144.99930           2         4019.0\n",
            "7           0    13335      2  ...   144.99540           2         4019.0\n",
            "...       ...      ...    ...  ...         ...         ...            ...\n",
            "13572     296    12200      2  ...   145.07878           2         2329.0\n",
            "13573     298     9938      4  ...   144.64789           6        16166.0\n",
            "13576     305    12234      3  ...   144.87904           6         6380.0\n",
            "13578     305    13311      4  ...   144.89299           6         6380.0\n",
            "13579     313    10776      4  ...   144.88449           6         6543.0\n",
            "\n",
            "[7130 rows x 18 columns]\n",
            "       Suburb  Address  Rooms  ...  Longtitude  Regionname  Propertycount\n",
            "0           0    12794      2  ...   144.99840           2         4019.0\n",
            "3           0     9004      3  ...   144.99690           2         4019.0\n",
            "5           0     2195      2  ...   144.99530           2         4019.0\n",
            "8           0    11082      1  ...   144.99730           2         4019.0\n",
            "10          0     9174      2  ...   145.00670           2         4019.0\n",
            "...       ...      ...    ...  ...         ...         ...            ...\n",
            "13569     293     1857      4  ...   145.22390           0         7082.0\n",
            "13570     293     7869      3  ...   145.22805           0         7082.0\n",
            "13574     301    12919      3  ...   144.89390           2         2474.0\n",
            "13575     302     1991      4  ...   145.16761           4         7392.0\n",
            "13577     305    12745      3  ...   144.88738           6         6380.0\n",
            "\n",
            "[6450 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4SF94d_OoMx"
      },
      "source": [
        "#The final step! \n",
        "\n",
        "Finally we reach point where we can use the machine learning method (if you are a begginner, notice how much time we spent in data transformation. Yeah, welcome to my life!).\n",
        "\n",
        "Like in many project, here, we will use the sklearn.linear_model library to retrieve the model and use training set information to calibrate the model. Then, missing values from BuildingArea are computed and assigned to the original dataframe. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCm5qTmkNouD",
        "outputId": "c5aab00f-bcd0-45b2-b343-35907149771d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_training, y_train)\n",
        "data.loc[data.BuildingArea.isnull(), 'BuildingArea'] = model.predict(x_test)\n",
        "\n",
        "print(data)\n",
        "\n",
        "print(data.BuildingArea.isnull().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Suburb  Address  Rooms  ...  Longtitude  Regionname  Propertycount\n",
            "0           0    12794      2  ...   144.99840           2         4019.0\n",
            "1           0     5943      2  ...   144.99340           2         4019.0\n",
            "2           0     9814      3  ...   144.99440           2         4019.0\n",
            "3           0     9004      3  ...   144.99690           2         4019.0\n",
            "4           0    10589      4  ...   144.99410           2         4019.0\n",
            "...       ...      ...    ...  ...         ...         ...            ...\n",
            "13575     302     1991      4  ...   145.16761           4         7392.0\n",
            "13576     305    12234      3  ...   144.87904           6         6380.0\n",
            "13577     305    12745      3  ...   144.88738           6         6380.0\n",
            "13578     305    13311      4  ...   144.89299           6         6380.0\n",
            "13579     313    10776      4  ...   144.88449           6         6543.0\n",
            "\n",
            "[13580 rows x 21 columns]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ooFR5sP5rp"
      },
      "source": [
        "#DONE!\n",
        "\n",
        "Now, it is your time to continue the example. You can use validation and/or correlation to make it more robust. Also, you can extend the idea to other numeric columns. \n",
        "\n",
        "Comment if you have other ideas of posts and tell me your opinion about this example!"
      ]
    }
  ]
}